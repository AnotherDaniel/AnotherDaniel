<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="https://www.danielkrippner.de/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.danielkrippner.de/" rel="alternate" type="text/html" /><updated>2023-08-01T14:20:11-05:00</updated><id>https://www.danielkrippner.de/feed.xml</id><title type="html">messages from ENV</title><subtitle>Musings, thoughts, documentation about things that I&apos;m doing to amuse myself</subtitle><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><entry><title type="html">Home Assistant integration for SMA PV system</title><link href="https://www.danielkrippner.de/sma-integration-in-ha" rel="alternate" type="text/html" title="Home Assistant integration for SMA PV system" /><published>2023-07-31T00:00:00-05:00</published><updated>2023-07-31T00:00:00-05:00</updated><id>https://www.danielkrippner.de/sma-integration-in-ha</id><content type="html" xml:base="https://www.danielkrippner.de/sma-integration-in-ha">&lt;p&gt;Earlier this year I’ve finally had a photovoltaic system installed in/on our house, and while three months later we still aren’t allowed to turn it on thanks to German bureaucracy, it does provide another playground for home automation integration. This should be easy, right? Our installation uses components from a major German supplier (SMA), there are HomeAssistant integrations for that.&lt;/p&gt;

&lt;p&gt;Well.&lt;/p&gt;

&lt;p&gt;Turns out that the inverter in our setup is of a new model line (SMA Tripower X), which isn’t supported by the official HomeAssistant integration. And while there exist individual data collection tools that can deal with this unit by scraping the parameter status information from it’s built-in web UI, and others that offer an architecture I liked, there was nothing out there combining the required device support, aesthetics and deployment options that I wanted.&lt;/p&gt;

&lt;h2 id=&quot;enter-smahub&quot;&gt;Enter smahub&lt;/h2&gt;

&lt;p&gt;Combining the above situation with a long-standing desire to “do something with Python” and use all of this to check out the utility of LLMs as swiss-army-knifes of programming helpers, I decided to roll my own SMA data aggregator/forwarder. The result is &lt;a href=&quot;https://github.com/AnotherDaniel/smahub&quot;&gt;smahub&lt;/a&gt;, which is a relatively straightforward combination of a central async-protected dictionary with a set of data source and data sink plugins.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;         +-------------+
         |    SMAHub   |
         +------+------+
                |
   +------------+-------------+
   |                          |
   v                          v      +--------+                +--------+    | Source |                |  Sink  |    +--------+                +--------+    | Plugin |                | Plugin |    +--------+                +--------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Essentially, smahub will spawn any configured source plugins, and these will begin to collect or snoop data from SMA devices. Any data points collected by these plugins are published into the central dictionary, which in turn is feeding sink plugins that (regularly or on-change) publish these data points to external consumers, e.g. publish to a MQTT broker.
For details, please look at the project README, plus the README files of the plugins that you are interested in. The code is open source and constructive criticism (aka pull requests) is welcome!&lt;/p&gt;

&lt;p&gt;All of the actual SMA device data ingest was taken from existing projects - shout-out and kudos to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sven (littleyoda) - &lt;a href=&quot;https://github.com/littleyoda/Home-Assistant-Tripower-X-MQTT&quot;&gt;Home-Assistant-Tripower-X-MQTT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Wenger Florian (datenschuft) - &lt;a href=&quot;https://github.com/datenschuft/SMA-EM&quot;&gt;SMA-EM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Currently, smahub supports a set of core plugins/SMA devices:&lt;/p&gt;

&lt;h3 id=&quot;tripower-x-inverters&quot;&gt;Tripower X inverters&lt;/h3&gt;

&lt;p&gt;These devices do offer a reduced modbus interface, which is not utilized by a smahub plugin at the moment as modbus data can be consumed by HomeAssistant directly.&lt;/p&gt;

&lt;p&gt;Another way to extract live data from the inverter is via its web interface; this is how Sven did it in Home-Assistant-Tripower-X-MQTT, and that is the approach I adopted for the TripowerX source plugin. Essentially, the plugin logs into the inverter web interface and will then periodically get the live-data parameter page, extracting all data points contained there. This usually works nicely, and provides a wealth of operational data that is not accessible otherwise. However, it can happen that the inverter refuses the login after too many attempts (excessive testing sessions…), making this channel somewhat erratic.&lt;/p&gt;

&lt;h3 id=&quot;sunny-home-manager-20-electric-meters&quot;&gt;Sunny Home Manager 2.0 electric meters&lt;/h3&gt;

&lt;p&gt;The other SMA device that is part of my setup is the Sunny Home Manager 2.0 (SHM2), which sits in the between the house mains and all connected consumers and suppliers in our house and measures how much electricity goes which way. SHM2 does not offer any interactive interface whatsoever, instead it periodically sends IP multicast messages (which miraculously also reach the SMA web portal to feed the manufacturer statistics and apps - anyone who knows why/how this works on network level, I’d be interested to learn) according to a SMA protocol called Speedwire. Luckily I did not have to get involved in the details of how to decode any of that, thanks to datenschufts SMA-EM project which has been there before. So I adopted Florians code into the smahub SHM2 plugin, which reads and decodes these periodic messages.&lt;/p&gt;

&lt;h3 id=&quot;mqtt-sink&quot;&gt;mqtt sink&lt;/h3&gt;

&lt;p&gt;The first data sink plugin I wrote was a very simple and straightforward MQTT publisher for the core smahub data dictionary. Essentially this either periodically and/or on-change writes datum/value pairs to MQTT topics, this can be complemented by a set of MQTT sensor configurations for HomeAssistant to make these items consumable there with decent names, unit definitions etc. - for more details on this, refer to the project and mqtt plugin docs, also including the gen_ha_sensors plugin if you want to auto-generate HomeAssistant config records yourself.&lt;/p&gt;

&lt;h3 id=&quot;ha_mqtt-sink&quot;&gt;ha_mqtt sink&lt;/h3&gt;

&lt;p&gt;Becaus semi-manually creating and maintaining HomeAssistant sensor configurations for all the data points collected by smahub is quite a chore, this plugin uses another Python library (ha_mqtt_discoverable) that automatically publishes all information to MQTT that HomeAssistant needs to perform auto-discovery and -configuration of MQTT sensor data. This works beautifully and seamlessly, and is the preferred option for HomeAssistant publication. One caveat is that the ha_mqtt_discoverable library does not offer an option to use non-standard MQTT broker ports, so if you need that you have to take a look at the mqtt sink plugin.&lt;/p&gt;

&lt;h2 id=&quot;ha-integration&quot;&gt;HA integration&lt;/h2&gt;

&lt;p&gt;With the ha_mqtt sink plugin, integration of smahub data into HomeAssistant is trivial - configure and start smahub, and things magically appear in HA’s MQTT integration. The HA Energy dashboard essentially needs three values to be useful:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Grid consumption: assign &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Power Consumption Counter&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Return to grid: assign &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Power Supply Counter&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Solar production: assign &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Power&lt;/code&gt; (sensor.power)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However! It does happen that the inverter rejects smahubs attempts to login and scrape the http parameter page, this happens in my case after excessive testing sessions where the device rejects further logins. This somewhat erratic behavior runs counter to my desire to have this part of my home data infrastructure be hassle-free and solid, which is why I decided on another way to get Tripower X data into HomeAssistant.&lt;/p&gt;

&lt;h2 id=&quot;modbus-after-all&quot;&gt;Modbus after all&lt;/h2&gt;

&lt;p&gt;This other way is to enable modbus on the inverter (via the device network configuration section), and directly snoop the modbus messages into HomeAssistant via the integrated modbus extension. The extension is included in HA by default, but does require manual sensor configuration via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configuration.yaml&lt;/code&gt;. I am including the modbus section below, this should only require putting in your device IP address to work:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;modbus&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMA&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;tcp&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;INVERTER IP&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;port&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;502&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;sensors&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_power_ac_raw&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;measurement&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;unit_of_measurement&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30775&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;uint32&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_power_ac_l1_raw&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;unit_of_measurement&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;measurement&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30777&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;int32&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_power_ac_l2_raw&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;unit_of_measurement&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;measurement&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30779&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;int32&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_power_ac_l3_raw&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;unit_of_measurement&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;measurement&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30781&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;int32&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_power_total_production&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;unit_of_measurement&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Wh&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;total_increasing&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;device_class&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;energy&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30513&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;int64&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;sma_status&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;slave&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;30201&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;scan_interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;15&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;data_type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;int32&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;sensor&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sma_power_ac&quot;&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;-&lt;/span&gt;
              
                
              
        &lt;span class=&quot;s&quot;&gt;unit_of_measurement: &quot;W&quot;&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;state_class: measurement&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This configuration gives you a sensor called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sma_power_total_production&lt;/code&gt;, which can be used instead of sensor.Power (see above) for getting information about PV-generation. Either way, smahub or modbus - this should set you with a working HomeAssistant Energy dashboard.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This would have been a very well-matched project for trialing Elixir, another todo on my list; however I wanted to painlessly reuse the SMA decoding code from the above mentioned projects, as well as offer a path of least resistance for anyone to complement and improve smahub in the future.&lt;/li&gt;
  &lt;li&gt;I think some minor fixes still needed - more robustness for the http scraper in the smahub TripowerX plugin, maybe a unit dimension conversion here or there…&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">Earlier this year I’ve finally had a photovoltaic system installed in/on our house, and while three months later we still aren’t allowed to turn it on thanks to German bureaucracy, it does provide another playground for home automation integration. This should be easy, right? Our installation uses components from a major German supplier (SMA), there are HomeAssistant integrations for that.</summary></entry><entry><title type="html">Using my own container registry</title><link href="https://www.danielkrippner.de/use-own-registry" rel="alternate" type="text/html" title="Using my own container registry" /><published>2022-05-22T00:00:00-05:00</published><updated>2022-05-22T00:00:00-05:00</updated><id>https://www.danielkrippner.de/use-own-registry</id><content type="html" xml:base="https://www.danielkrippner.de/use-own-registry">&lt;p&gt;This will be a short update - just to be consistent about where I describe my configuration gimmicks if I ever need to look things up in the future :-)
The problem that is solved in this article is the fact that the Docker Hub free tier only allows hosting of one container image. As I’m already using this freebie for my &lt;a href=&quot;https://www.danielkrippner.de/airprint&quot;&gt;Airprint Relay&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/repository/docker/agoodcontainer/airprint-relay&quot;&gt;image&lt;/a&gt;, the recently built &lt;a href=&quot;https://www.danielkrippner.de/nextcloud-backup&quot;&gt;nextcloud-backup&lt;/a&gt; image requires a different solution.&lt;/p&gt;

&lt;h2 id=&quot;all-has-been-prepared&quot;&gt;All has been prepared&lt;/h2&gt;

&lt;p&gt;If you don’t want to pay for a service, you host your own - which is what I set up many months ago when I came across Docker Hub’s own &lt;a href=&quot;https://hub.docker.com/_/registry&quot;&gt;registry container image&lt;/a&gt;. This is the docker-compose file I use:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3&apos;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;registry&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry:2&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5000:5000&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unless-stopped&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry-data:/var/lib/registry&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry-ui-net&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;healthcheck&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;wget -q --spider http://localhost:5000 &amp;amp;&amp;gt;/dev/null || exit &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;interval&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;0m43s&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;10s&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;retries&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;

  &lt;span class=&quot;na&quot;&gt;ui&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry_ui&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;joxit/docker-registry-ui:latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;5080:80&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SINGLE_REGISTRY=true&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;REGISTRY_TITLE=Homecentral Docker Registry&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;NGINX_PROXY_PASS_URL=http://registry:5000&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;depends_on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unless-stopped&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;depends_on&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;registry-ui-net&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;networks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;registry-ui-net&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;registry-data&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Straightforward - I’m just adding a second container to give me a lightweight UI for the registry. Really lightweight, but better than nothing! Note that this is running in my private home network, no links into that from the outside, so I’m not bothering with security, certificates, accounts etc.&lt;/p&gt;

&lt;h2 id=&quot;using-my-own-registry&quot;&gt;Using my own registry&lt;/h2&gt;

&lt;p&gt;Using a custom container registry is also straightforward - there are two aspects to this: push an image to the registry, and pull from the registry when starting a container.
The push part requires the image in question to be tagged with the URL of our custom registry, then that tagged image needs to be pushed. This is for scenarios where e.g. an image was built locally, then we push it to our custom registry to make it available in our network:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker tag &amp;lt;image_name&amp;gt; &amp;lt;host_url&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;image_name&amp;gt;
docker push &amp;lt;host_url&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;image_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once the image is available on the registry (e.g., check via the UI) it can be pulled via docker-compose (or whatever rocks your boat) - I’m providing a sample configuration for the nextcloud-backup container:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.7&apos;&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;nxtcldbackup&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;host_url&amp;gt;:&amp;lt;port&amp;gt;/&amp;lt;image_name&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nxtcld-backup&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unison-conf:/root/.unison&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/mnt/nextcloud:/mnt/source&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/mnt/raid1/nextcloud:/mnt/backup&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;unison-conf&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That’s it - this way we push a container image to our custom registry, and docker-compose will pull it from there when running the container.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Nothing really. No surprises this week.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">This will be a short update - just to be consistent about where I describe my configuration gimmicks if I ever need to look things up in the future :-) The problem that is solved in this article is the fact that the Docker Hub free tier only allows hosting of one container image. As I’m already using this freebie for my Airprint Relay image, the recently built nextcloud-backup image requires a different solution.</summary></entry><entry><title type="html">Backing up a nextcloud file share via webdav</title><link href="https://www.danielkrippner.de/nextcloud-backup" rel="alternate" type="text/html" title="Backing up a nextcloud file share via webdav" /><published>2022-05-20T00:00:00-05:00</published><updated>2022-05-20T00:00:00-05:00</updated><id>https://www.danielkrippner.de/nextcloud-backup</id><content type="html" xml:base="https://www.danielkrippner.de/nextcloud-backup">&lt;p&gt;The first question after having &lt;a href=&quot;https://www.danielkrippner.de/raspi-NAS&quot;&gt;set up a NAS&lt;/a&gt;: what could we use it for? Mine is already running a timemachine server, but that’s barely making a dent in the disk space utilization of the system. Well, the one entity that stores almost all of our pictures, music, documents, and everything else is a nextcloud instance that is synced across all relevant devices. It has it’s own existing backup strategy, and I excluded it from the Mac’s timemachine scope for that reason - but now that we have our own storage option, why not add a backup path there? One more replica, one more physical location, one more fallback option.&lt;/p&gt;

&lt;h2 id=&quot;accessing-the-nextcloud-share&quot;&gt;Accessing the nextcloud share&lt;/h2&gt;

&lt;p&gt;The two obvious options for accessing the nextcloud file share that we are using are the &lt;a href=&quot;https://docs.nextcloud.com/desktop/latest/advancedusage.html#nextcloud-command-line-client&quot;&gt;nextcloud-cmd client&lt;/a&gt;, and the webdav protocol used by nextcloud to enable filesystem-style access. Normally the official nextcloud client would be the preferred option, but there are two major snags in this case:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the nextcloud client comes with UI support and pulls in 100s of megabytes of related packages that we neither need nor want on the NAS machine&lt;/li&gt;
  &lt;li&gt;as far as I could see, the client offers no option to define a one-way sync (mirroring) setup - but in the context of a backup solution, I definitely do not want any propagation from backup to server&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So webdav to the rescue… ? The good part is that there is an option to mount webdav shares directly into the file system via &lt;a href=&quot;https://en.wikipedia.org/wiki/Davfs2&quot;&gt;davfs2&lt;/a&gt; - and when that is possible we can mount the nextcloud share read-only, plus use all kinds of filesystem-based tools for synchronization.&lt;/p&gt;

&lt;h2 id=&quot;choosing-a-file-synchronizer-tool&quot;&gt;Choosing a file synchronizer tool&lt;/h2&gt;

&lt;p&gt;The bad part about webdav is that it’s not fast. At all. The nextcloud share in question contains &amp;gt;160 GB of data, distributed across many 10.000s of files. The first synchronization attempt with rsync turned out to be a non-starter, as even comparing existing files took upwards of half a second (per file) in my setup. The usual performance optimization options didn’t do anything to help.
There are other options for file synchronization, however, for example the venerable &lt;a href=&quot;https://www.cis.upenn.edu/~bcpierce/unison/&quot;&gt;unison file synchronizer&lt;/a&gt;. I’ve been using unison in various contexts over the years, so this is what I tried next. And it did not disappoint! After a looong initial synchronization run, subsequent daily syncs just take a couple of minutes. With that, we have an option to access the nextcloud file share and found a tool that works reasonably well for performing the actual synchronization.&lt;/p&gt;

&lt;h2 id=&quot;backup-strategy&quot;&gt;Backup strategy…&lt;/h2&gt;

&lt;p&gt;With the basics in place, the next step is deciding on a backup strategy. Ours is very uninspired:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I want a daily synchronization from the nextcloud file server to a local copy&lt;/li&gt;
  &lt;li&gt;this daily copy should be mirrored to a weekly copy once every week (duh)&lt;/li&gt;
  &lt;li&gt;this weekly copy gets archived to “long-term storage” tar balls once a month&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the first two activities I will use unison, the third will be handled by good old &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tar&lt;/code&gt; + compression.&lt;/p&gt;

&lt;h2 id=&quot;-and-implementation&quot;&gt;… and implementation&lt;/h2&gt;

&lt;p&gt;The most direct way to implement the desired backup actions would be crond on the NAS host linux system. But that is too simple, right? Also, I am trying to minimize the scope of configuration I’m doing on the host system, to minimize effort involved for future re-creation of these systems.
So the plan is to use crond inside a minimal docker container, which mounts the source and backup file system folders of the host system. This way, reinstating the backup setup is as simple as cloning the docker build files from github and running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker-compose up&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-swearing&quot;&gt;The Swearing&lt;/h2&gt;

&lt;p&gt;So far so simple - minimal docker base images usually means Alpine Linux, and setting this up with unison, unison profiles and simple crond configuration is a matter of minutes. Or so I thought.
It turned out that I could do whatever I wanted - the Alpine (busybox) crond implementation didn’t care. It happily accepts my crontab configuration. It starts and runs fine. But it doesn’t move one finger to actually execute what’s defined in the crontab. I tried removing the newfangled &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/periodic&lt;/code&gt; stuff, tried all kinds of simplistic example configurations, even looked through the busybox crond code a little bit, no joy. But looking through that code gave me the prompt to try the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/periodic&lt;/code&gt; approach, which works as it turned out! What the heck…
So I decided to forgo the option to precisely define the starting time of my backup scripts, and instead use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/periodic&lt;/code&gt; - at that point I had already spend three evenings trying to get busybox crond to work and wanted to move on.&lt;/p&gt;

&lt;h2 id=&quot;the-result&quot;&gt;The Result&lt;/h2&gt;

&lt;p&gt;The entire backup container project can be found &lt;a href=&quot;https://github.com/AnotherDaniel/nxtcldbackup&quot;&gt;on github&lt;/a&gt;. The upshot is that this docker-compose file allows building of the container image with one &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker-compose build&lt;/code&gt; command:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.7&apos;&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;nxtcldbackup&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;nxtcld-backup&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;dockerfile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;alpine.dockerfile&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;true&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SOURCE=/mnt/source&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;BACKUP=/mnt/backup&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unison-conf:/root/.unison&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/mnt/nextcloud:/mnt/source&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/mnt/raid1/nextcloud:/mnt/backup&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;unison-conf&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There is a reason why I chose to handle the unison configuration directory (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/root/.unison&lt;/code&gt;) via docker volume: this is the place where unison keeps it’s synchronization data, so it is desirable to keep that directory persistent across container restarts. At the same time, I didn’t want these synchronization status files to pollute my host file system, which is why I decided to go with a docker volume and add the unison profiles at container build time:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;FROM alpine:latest&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;RUN apk add --update rsync unison &amp;amp;&amp;amp; rm -rf /var/cache/apk/*&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;COPY entrypoint.sh /entrypoint.sh&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;RUN chmod +x /entrypoint.sh&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;COPY periodic /etc/periodic&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;RUN chmod -R +x /etc/periodic&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# This directory holds unison config profiles, but also the unison sync&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# reports/datasets. To have this work properly (profiles should be there,&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# but also the sync reports should be persistent across container restarts),&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# this directory should be done as a volume-mount when running the container.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# ATTENTION: to make a rebuild pick up changes here, remove this volume manually!&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#   docker volume rm nxtcldbackup_unison-conf&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;RUN mkdir /root/.unison&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;COPY unison/* /root/.unison/&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;ENTRYPOINT [&quot;/entrypoint.sh&quot;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# -f | Foreground&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;CMD [&quot;crond&quot;, &quot;-f&quot;, &quot;-d&quot;, &quot;8&quot;, &quot;-c&quot;, &quot;/etc/crontabs&quot;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As stated in the comment above, some care needs to be taken when trying to update/change the unison profile configuration on a system where a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;unison-conf&lt;/code&gt; docker volume already exists: rebuilding the container will not change the files in that volume, so in that case either remove the existing volume with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker volume rm nxtcldbackup_unison-conf&lt;/code&gt;, or copy the profile files into the running container (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;docker cp foo.txt container_id:/foo.txt&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The unison profiles and crond scripts are very straightforward, and can be found in the github repository.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;I am 66% certain that busybox crond is currently broken, as it steadfastly ignores crontab configuration other than the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/periodic&lt;/code&gt; hooks&lt;/li&gt;
  &lt;li&gt;unison is really deserving more attention - it is robust, reliable and fast; the only thing I’m missing is a configuration option to determine storage location for the synchronization database files&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">The first question after having set up a NAS: what could we use it for? Mine is already running a timemachine server, but that’s barely making a dent in the disk space utilization of the system. Well, the one entity that stores almost all of our pictures, music, documents, and everything else is a nextcloud instance that is synced across all relevant devices. It has it’s own existing backup strategy, and I excluded it from the Mac’s timemachine scope for that reason - but now that we have our own storage option, why not add a backup path there? One more replica, one more physical location, one more fallback option.</summary></entry><entry><title type="html">NAS setup with an Argon EON</title><link href="https://www.danielkrippner.de/raspi-NAS" rel="alternate" type="text/html" title="NAS setup with an Argon EON" /><published>2022-05-18T00:00:00-05:00</published><updated>2022-05-18T00:00:00-05:00</updated><id>https://www.danielkrippner.de/raspi-NAS</id><content type="html" xml:base="https://www.danielkrippner.de/raspi-NAS">&lt;p&gt;Looks like I am on a kind of ‘Argon run’ this quarter: since I upgraded the &lt;a href=&quot;https://www.danielkrippner.de/M2-for-raspi&quot;&gt;Argon One case to run off an M.2 drive&lt;/a&gt;, due to a stroke of lucky timing I managed to get an &lt;a href=&quot;https://www.argon40.com/products/argon-eon-pi-nas&quot;&gt;Argon Eon NAS case&lt;/a&gt; at a very fair price point - looking at the recent Shanghai supply situation, I consider myself lucky I got one at all!&lt;/p&gt;

&lt;p&gt;I always fancied the idea of running a NAS in my home network, and regularly ogled the Synology products with my finger hovering over the buy-button. What held me back was the need-vs-pricepoint aspect, and the fact that I’d rather build a system from scratch. So that is where the Argon EON case comes in and pushes all the relevant switches - stylish, practical, put a Raspi and some disks in, voila!&lt;/p&gt;

&lt;p&gt;My initial use cases are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;running a timemachine capsule (now that I’m a Mac user!)&lt;/li&gt;
  &lt;li&gt;doing my own backup of nextcloud-hosted data (in addition to the very professional service I’m privileged to be able to use)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-box&quot;&gt;The box&lt;/h2&gt;

&lt;p&gt;The Argon Eon is all I expected it to be. It comes in a nice box with professional packaging, and is a robust, solid-feeling affair that is cleverly designed and a joy to look at and handle. The highlight: it includes a seriously fantastic screwdriver! The one thing that I wasn’t aware of pre-buy is that the case only has room for two 3.5” and two 2.5” hard disks - was expecting four 3.5”-sized bays. Not a realistic expectation considering the overall dimensions of the Eon, but I didn’t really think about that up front.&lt;/p&gt;

&lt;p&gt;Installing the parts is what I can only describe as immensely satisfying. Sounds silly, but the scredriver that comes with the Eon is pure bliss. The box is very accessible when removing the two (magnet-held) covers, and while getting the raspi 4 board in place with the ports lined up properly takes a few mindful moments, putting everything together is obvious, easy and satisfying. I chose to run the raspberry operating system off a USB(3) drive located on the main-board, to have a clear separation between system and storage concerns.&lt;/p&gt;

&lt;h2 id=&quot;my-personal-startup-challenges&quot;&gt;My personal startup challenges&lt;/h2&gt;

&lt;p&gt;This is not something that will necessarily recur for other users - but I did have a really hard time getting the initial Ubuntu system to my desired state. My setup happened right around the time when Ubuntu 22.04 came out - but I initially attempted to install the previous LTS version and upgrade from there, no joy at all. The update process hung endlessly, doing (or not doing) unfathomable things with no feedback about what was going awry. I tried running this from the SD card, the USB drive, no difference. Then after some googling I managed to find the brand-new raspberry image of &lt;a href=&quot;https://ubuntu.com/download/raspberry-pi&quot;&gt;22.04 server&lt;/a&gt;, which worked from the get-go - so a lot of hand-wringing about nothing. In retrospect I am certain that the Raspberry Ubuntu Server image only became available after I had spent a day trying to upgrade the older version, but that might be just me justifying my excitement getting this Raspberry board set up ;-)&lt;/p&gt;

&lt;p&gt;The final snap was when I had the base system up running beautifully off it’s USB drive, had that cloned to a SD card for good measure, and then went and installed the hard disk drives. For reasons I still don’t understand, that completely removed any usb disk devices from the Ubuntu system. The new harddisks didn’t show up, and the USB drive supposed to be the boot device also was gone (with the system happily booting off the SD card I cloned to earlier). Googling et al didn’t help me figure out what went wrong or how to fix this, so I went and reinstalled everything, again. For some reason this time all went well up to and including installation of the spinning disks, at which point I was finally able to go ahead with configuring them into a raid 1 array - see next section.&lt;/p&gt;

&lt;h2 id=&quot;raid-setup&quot;&gt;RAID setup&lt;/h2&gt;

&lt;p&gt;What to do with the disk-bay size options of the Argon Eon? Originally I was thinking along a &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_5&quot;&gt;raid level 5&lt;/a&gt; setup using three disks, with an option to add a fourth later. Not primarily because I need the space, but because raid 5 always felt like the best compromise between disk space overhead and redundancy. After doing some shopping-research around NAS disk drives and seeing that there’s some useful options for 3.5”, but no dedicated ones for 2.5”, I decided to go with a &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_1&quot;&gt;raid level 1&lt;/a&gt; setup with two 3.5” NAS-optimized hard disk drives. In my case I optimized disk selection for energy consumption and price point, settling on two 4TB drives for my initial setup. I can always add one or two 2.5” drives to that cluster and promote it to raid 5 - there are no dedicated NAS options in that size category, but should I need more disk space there at least are ample options for 2.5” spinning metal in the 4TB class.&lt;/p&gt;

&lt;p&gt;Once these decisions were made, the drives ordered and delivered, the actual raid setup was anticlimatic. There are myriad guides out there, one of the ones I was looking at is &lt;a href=&quot;https://www.ricmedia.com/build-raspberry-pi3-raid-nas-server/&quot;&gt;this one&lt;/a&gt;. Having a raid 1 partition running, I’m now looing at an Ubuntu 22.04 LTS installation with some personalization options like &lt;a href=&quot;https://ohmyz.sh&quot;&gt;oh-my-zsh&lt;/a&gt;, the raid cluster mounted into the file system, and the usual docker and docker-compose tools that I want for all the productive workloads.&lt;/p&gt;

&lt;h2 id=&quot;timemachine-capsule-setup&quot;&gt;Timemachine capsule setup&lt;/h2&gt;

&lt;p&gt;Running a timemachine backup server for MacOS is a very straighforward thing - there exist a number of docker hub images for the task. As always the selection process involves availability of reasonable documentation (indicating aspiration), recent updates (inidicating commitment) and of course availability for the Raspberry target platform. In my case I went with &lt;a href=&quot;https://hub.docker.com/r/mbentley/timemachine&quot;&gt;mbentley’s timemachine image&lt;/a&gt; which ticks all these boxes.
Getting this running is trivial, based off the following docker-compose file:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3.7&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;timemachine&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;network_mode&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;host&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CUSTOM_SMB_CONF=false&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;CUSTOM_USER=false&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;DEBUG_LEVEL=1&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;EXTERNAL_CONF=&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;HIDE_SHARES=no&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MIMIC_MODEL=TimeCapsule8,119&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TM_USERNAME=timemachine&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TM_GROUPNAME=timemachine&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TM_UID=1111&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TM_GID=1111&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;PASSWORD=timemachine&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SET_PERMISSIONS=false&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SHARE_NAME=TimeMachine&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMB_INHERIT_PERMISSIONS=no&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMB_NFS_ACES=yes&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMB_METADATA=stream&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMB_PORT=445&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SMB_VFS_OBJECTS=acl_xattr fruit streams_xattr&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;VOLUME_SIZE_LIMIT=0&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;WORKGROUP=WORKGROUP&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ADVERTISED_HOSTNAME=nas&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unless-stopped&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;/mnt/raid1/timemachine:/opt/timemachine&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;timemachine-var-lib-samba:/var/lib/samba&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;timemachine-var-cache-samba:/var/cache/samba&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;timemachine-run-samba:/run/samba&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;ulimits&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;nofile&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;soft&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;65536&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;hard&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;65536&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;timemachine&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;mbentley/timemachine:smb&lt;/span&gt;

&lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;timemachine-var-lib-samba&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;timemachine-var-cache-samba&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;timemachine-run-samba&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that my setup includes a user and group on the host machine matching this docker-compose definition, named “timemachine” with uid/guid 1111. Also, evidently, my raid disk is located at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/mnt/raid1/&lt;/code&gt;, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timemachine/&lt;/code&gt; subdirectory is used for storing mbentley/timemachine backups.&lt;/p&gt;

&lt;h2 id=&quot;one-more-thing&quot;&gt;One more thing&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.danielkrippner.de/M2-for-raspi&quot;&gt;As with the Argon One&lt;/a&gt;, I also run a fork of the Argon software on the Eon - done by Jeff Curless who is very &lt;a href=&quot;https://forum.argon40.com/t/extending-the-oled-screens/545&quot;&gt;supportive and comprehensive&lt;/a&gt; with his &lt;a href=&quot;https://github.com/JeffCurless/argoneon&quot;&gt;improved version of the original Argon code&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;first-step-done&quot;&gt;First step: done&lt;/h2&gt;

&lt;p&gt;This is sufficient to have a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;timemachine&lt;/code&gt; backup server appear in my Mac timemachine preferences dialog and the Mac happily use it for timemachine backups.
I will look into my backup scenario for nextcloud data in a separate article.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Argon40 have again put together something cool with the Argon Eon NAS case&lt;/li&gt;
  &lt;li&gt;Hosting your own timemachine server is trivial, thanks to the efforts of others&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">Looks like I am on a kind of ‘Argon run’ this quarter: since I upgraded the Argon One case to run off an M.2 drive, due to a stroke of lucky timing I managed to get an Argon Eon NAS case at a very fair price point - looking at the recent Shanghai supply situation, I consider myself lucky I got one at all!</summary></entry><entry><title type="html">Migrating a Raspi setup to USB/SATA</title><link href="https://www.danielkrippner.de/M2-for-raspi" rel="alternate" type="text/html" title="Migrating a Raspi setup to USB/SATA" /><published>2022-04-07T00:00:00-05:00</published><updated>2022-04-07T00:00:00-05:00</updated><id>https://www.danielkrippner.de/M2-for-raspi</id><content type="html" xml:base="https://www.danielkrippner.de/M2-for-raspi">&lt;p&gt;My home IT infrastructure currently runs off a single trusty Raspberry Pi 4B - that’s around 30 containerized apps from DNS filter/proxy, Home Assistant et al for home automation, document management system, to printer proxy, vehicle data logger, and more. The Pi is an amazingly good fit for this purpose, especially since I’ve put it into the fantastic &lt;a href=&quot;https://www.argon40.com/products/argon-one-v2-case-for-raspberry-pi-4&quot;&gt;Argon One case&lt;/a&gt; for decent cooling, robustness and visual appeal. It’s been chugging away silently and reliably for some years now, but there were two things that nagged me: disk IO with the SD card is workable but far from snappy, plus the questionable long-term reliability of that SD card.&lt;/p&gt;

&lt;p&gt;Turns out there is a solution for that! Argon has introduced a &lt;a href=&quot;https://www.argon40.com/products/argon-one-m-2-expansion-board&quot;&gt;M.2 disk ‘shelf’&lt;/a&gt; that simply replaces&amp;amp;extends the original Argon One case, and connects to one of the Raspi’s USB3 ports! (They probably introduced that quite some time ago, but I only now stumbled across it while trying to purchase their new &lt;a href=&quot;https://www.argon40.com/products/argon-eon-pi-nas&quot;&gt;Raspi-based NAS case&lt;/a&gt;. Enough with the product placement now, though!)&lt;/p&gt;

&lt;h2 id=&quot;phyiscal-installation---boring&quot;&gt;Phyiscal installation - boring&lt;/h2&gt;

&lt;p&gt;Ordered the M.2 shelf plus a matching M.2 SATA SSD drive a couple of days back, arrived yesterday. And because I cannot resist tinkering for long, I went ahead and put things together the same day. The physical side of the installation is completely boring, as expected: unscrew original case bottom, place M.2 disk in new shelf, screw back in place, connect USB plug - done. As might have become apparent in the intro, I like Argon 40 products - well designed, good fit, high quality build.&lt;/p&gt;

&lt;h2 id=&quot;system-migration&quot;&gt;System migration&lt;/h2&gt;

&lt;p&gt;More interesting than the physical install was moving my entire system from the SD card over to the SSD. Well in actuality it was completely painless and only took 10 minutes - had I confidently known all the really necessary steps from the beginning :-)
The issue I had was to figure out - from dozens of articles and blog posts, written over the course of the last 1-3 years - which steps were actually really necessary in my setup. Not very many, it turned out - but I definitely took a lot longer than 10 minutes to get there.&lt;/p&gt;

&lt;h3 id=&quot;context-prerequisites&quot;&gt;Context, prerequisites&lt;/h3&gt;

&lt;p&gt;Up front the context stuff: my Raspi is running 21.10 Ubuntu 64bit server edition. The Raspi’s bootloader was already updated to the latest version. I’m running some minor modifications to the boot/kernel-related things (see &lt;a href=&quot;https://www.danielkrippner.de/dockerdeconz&quot;&gt;Deploy Deconz zigbee control software via docker&lt;/a&gt;), but nothing that has any impact on disk migration.&lt;/p&gt;

&lt;h3 id=&quot;raspi-boot-order&quot;&gt;Raspi boot order&lt;/h3&gt;

&lt;p&gt;The Raspberry Pi 4B can boot from SD card or USB drive - and there is a bootloader option to tell it which to try first. Ultimately this is not really important other than maybe shaving of a little bit of time from your boot process - I set it to try USB first, like this (&lt;a href=&quot;https://www.raspberrystreet.com/learn/how-to-boot-raspberrypi-from-usb-ssd&quot;&gt;original source&lt;/a&gt;):&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;rpi-eeprom-config

&lt;span class=&quot;c&quot;&gt;# Take note of the BOOT_ORDER code. The defualt code is 0xf41 and is read right to left to determine the boot order. &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 1 = Check SD card&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# 4 = Check USB drive&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# f = Start again&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# This boot order is exactly what we want. If the boot order code is anything other than 0xf41, you can change the boot configuration using this command. &lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-E&lt;/span&gt; rpi-eeprom-config &lt;span class=&quot;nt&quot;&gt;--edit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the rpi-eeprom-config command comes with the rpi-eeprom package&lt;/li&gt;
  &lt;li&gt;there are other ways to set boot order, e.g. by &lt;a href=&quot;https://www.tomshardware.com/how-to/boot-raspberry-pi-4-usb&quot;&gt;running a raspian image configured for this purpose&lt;/a&gt; - whatever rocks your boat, I guess&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;disk-cloning&quot;&gt;Disk cloning&lt;/h3&gt;

&lt;p&gt;This part I expected to be the most daunting - but as usual, someone has been here before and &lt;a href=&quot;https://github.com/billw2/rpi-clone&quot;&gt;hewn a path&lt;/a&gt;. With Bill Wilson’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rpi-clone&lt;/code&gt; script disk cloning is completely anticlimatic - again, especially once you know what you’re doing. In my case the relevant learnings include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;when cloning to an empty disk, the tool asks for a label for that disk (the big/root partition): if you plan to migrate to that disk, put &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writable&lt;/code&gt; as the label (more on that in the next section)&lt;/li&gt;
  &lt;li&gt;other than that, none of the more elaborate tool options are required - simply do &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo rpi-clone sda&lt;/code&gt; (sda being the device name of the disk to clone to)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There might have been a couple of questions asked during the process, but nothing surprising or difficult (otherwise I would have remembered).&lt;/p&gt;

&lt;h3 id=&quot;boot-configuration&quot;&gt;Boot configuration&lt;/h3&gt;

&lt;p&gt;Now this is where the largest part of my research and trial went - entirely uncalled for in hindsight, as is normal. The key thing I wanted: boot from the new disk, mount all partitions from the new disk, do not use the SD card anymore.
With the Ubuntu installation I’m using this is a complete no-brainer, as in:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;boot config (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/boot/firmware/cmdline.txt&lt;/code&gt;) and mount config (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/fstab&lt;/code&gt;) use disk labels&lt;/li&gt;
  &lt;li&gt;the identification label for the main (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&lt;/code&gt;) partition is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writable&lt;/code&gt;, the firmare (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/boot/firmware&lt;/code&gt;) partition label is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;system-boot&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So the two corresponding partitions created on the cloned SATA disk by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rpi-clone&lt;/code&gt; need to be labelled accordingly, and we’re done. The main partition is of type ext4, so to set the label/name to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;writable&lt;/code&gt; we use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e2label&lt;/code&gt; tool, like this: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo e2label /dev/sda2 writable&lt;/code&gt;. (If you pay attention during the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rpi-clone&lt;/code&gt; process for a fresh disk, you can directly assign that label then.)&lt;/p&gt;

&lt;p&gt;The other partition (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/sda1&lt;/code&gt;) contains firmware and boot-related stuff, and for some reason is of type vfat. There exists a tool called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mlabel&lt;/code&gt; (from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mtools&lt;/code&gt;) package. However, this utility is too much in line with Windows conventions, and only assigns uppercase-letter labels - so whatever you put in, the disk label ends up being &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SYSTEM-BOOT&lt;/code&gt;. The standard installation (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/fstab&lt;/code&gt;) is looking for a lowercase &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;system-boot&lt;/code&gt;, however. So either modify the fstab entry to uppercase letters, or there is another little utility to the rescue: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo fatlabel /dev/sda1 system-boot&lt;/code&gt; will do what we want and expect.&lt;/p&gt;

&lt;p&gt;To get a nice list of the block devices in your system, and their fs-types, mountpoints and &lt;strong&gt;labels&lt;/strong&gt;, you can use this command: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo blkid -o list&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;thats-it-were-done&quot;&gt;That’s it, we’re done&lt;/h2&gt;

&lt;p&gt;And this is all - with those changes the raspberry boots entirely off the USB/SATA drive, the SD card is no longer needed! It can still be used though - for example as a fallback option. Because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo rpi-clone mmcblk0&lt;/code&gt; will now clone the contents of the main drive to the sd card, and thus provide an excellent, build-in safety net for disk failures.&lt;/p&gt;

&lt;p&gt;Running on the M.2 disk makes the Raspi feel like a new machine - it feels an order of magnitude more responsive even in simple ssh sessions. For that alone the upgrade is worth it. Of course all the hosted applications benefit from the massive speed increase, especially disk-heavy solutions like docspell.&lt;/p&gt;

&lt;p&gt;With regards to reliability there is a lot left to chance (I’ve never had disk problems in my life so far, no matter what technology) - the M.2 disk might fail tomorrow while the SD card soldiers on forever, or the other way around. However the chances should be a lot better with the M.2 version, and having the SD card still in the system as a backup option is a definitive upside.&lt;/p&gt;

&lt;p&gt;Side note: while the Argon 40 hardware products are beautiful, their software tools (eg for case fan control) are on the ‘meh’ side (as in, not really working on my vanilla Ubuntu setup). And again someone has fixed that for us and provided a more robust, elegant solution - more than one person, actually. I am running &lt;a href=&quot;https://gitlab.com/DarkElvenAngel/argononed&quot;&gt;argononed from DarkElvenAngel&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The gen4 Raspi is a very capable platform for running a bunch of home IT concerns - even with the modest 4GB version,&lt;/li&gt;
  &lt;li&gt;… but a USB/SATA disk upgrade &lt;strong&gt;massively&lt;/strong&gt; boosts disk IO performance, and is worth it for that alone.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">My home IT infrastructure currently runs off a single trusty Raspberry Pi 4B - that’s around 30 containerized apps from DNS filter/proxy, Home Assistant et al for home automation, document management system, to printer proxy, vehicle data logger, and more. The Pi is an amazingly good fit for this purpose, especially since I’ve put it into the fantastic Argon One case for decent cooling, robustness and visual appeal. It’s been chugging away silently and reliably for some years now, but there were two things that nagged me: disk IO with the SD card is workable but far from snappy, plus the questionable long-term reliability of that SD card.</summary></entry><entry><title type="html">Nextcloud CLI shell script</title><link href="https://www.danielkrippner.de/nextcloud-cli" rel="alternate" type="text/html" title="Nextcloud CLI shell script" /><published>2022-02-19T00:00:00-06:00</published><updated>2022-02-19T00:00:00-06:00</updated><id>https://www.danielkrippner.de/nextcloud-cli</id><content type="html" xml:base="https://www.danielkrippner.de/nextcloud-cli">&lt;p&gt;With the recent instantiation of my &lt;a href=&quot;https://www.danielkrippner.de/scanningstation&quot;&gt;simple scanning station&lt;/a&gt;, there is now another data sink in my home network that wants backup. And in the case of the docspell database, we’re looking at quite relevant data, so a backup definitely is called for.
Where backups are concerned I am partial to the dandelion strategy: spread your data around often, and to all kinds of places. One of the locations that I like to use is the &lt;a href=&quot;https://nextcloud.com&quot;&gt;Nextcloud&lt;/a&gt; instance that is covering all our “Cloud data” needs.&lt;/p&gt;

&lt;h2 id=&quot;nextcloud-interaction-options&quot;&gt;Nextcloud interaction options&lt;/h2&gt;

&lt;p&gt;Nextcloud offers a sync client for most platforms, of course including Linux (my scanning station is running on Ubuntu, on a Raspberry Pi). However, that default client is a GUI application. My Raspi is running headless, and I don’t want to pull in dozens of additional packages to run a desktop that I’ll never use. Also, for the use case at hand I simply want to push some files into Nextcloud, no fancy syncing required.&lt;/p&gt;

&lt;p&gt;What I need is a simply command-line interface for file upload, that I can use from a cron script that will periodically push backup files to the Nextcloud server. Nextcloud offers a &lt;a href=&quot;https://docs.nextcloud.com/server/latest/developer_manual/client_apis/WebDAV/basic.html&quot;&gt;WebDAV interface for basic file functions&lt;/a&gt;, and that means that some scripting around &lt;a href=&quot;https://curl.se&quot;&gt;curl&lt;/a&gt; should be enough.&lt;/p&gt;

&lt;h2 id=&quot;that-escalated-quickly&quot;&gt;That escalated quickly&lt;/h2&gt;

&lt;p&gt;Ok then - a while ago I already wrote a simple script to just push a file to a specified location on a Nextcloud file server. I also had a second script that could delete a file/folder. Wouldn’t it be nice if there was a full command-line interface (CLI) client that could do it all? File upload and download, deletion, directory creation, useful error handling?&lt;/p&gt;

&lt;p&gt;Of course it would!&lt;/p&gt;

&lt;p&gt;So that’s what I build the last couple of evenings - the result can be found &lt;a href=&quot;https://github.com/AnotherDaniel/nx_client&quot;&gt;here&lt;/a&gt;.
It is a reasonably complete nextcloud files cli, including some ‘fancy’ options like checking whether a file already exists before uploading.&lt;/p&gt;

&lt;h2 id=&quot;nx_client-usage&quot;&gt;nx_client usage&lt;/h2&gt;

&lt;p&gt;Nextcloud cli for downloading/uploading/deleting files&lt;/p&gt;

&lt;p&gt;Usage: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nx_client.sh [-h] [-c &amp;lt;configfile&amp;gt;] [-u &amp;lt;file&amp;gt; -f | -p | -d | -o] &amp;lt;destination&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&amp;lt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;destination&lt;/code&gt;&amp;gt; is the location on your nextcloud file server instance, starting from the root folder.
Nextcloud credentials and settings are sourced from ~/.nx_client&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-man&quot;&gt;Options:
                no option will download the file at &amp;lt;destination&amp;gt; to the current directory
 -o &amp;lt;file&amp;gt;      download file at &amp;lt;destination&amp;gt; to local &amp;lt;file&amp;gt;
 -u &amp;lt;file&amp;gt;      upload &amp;lt;file&amp;gt; to &amp;lt;destionation&amp;gt;, if it doesn&apos;t already exist
 -f             force re-upload of &amp;lt;file&amp;gt; even if it already exists
 -d             delete file or directory at &amp;lt;destionation&amp;gt;
 -p             create &amp;lt;destination&amp;gt; directory
 -c             nextcloud configuration file to use, defaults to ~/.nx_client
 -h             display this help

The configuration file (default: ~/.nx_client) needs to define the variables BASEURL and CREDS - for example:
 BASEURL=&quot;https://example.nextcloud.host/remote.php/webdav&quot;
 CREDS=&quot;example@user.account:examplePassword&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;skipping-the-boring-bits&quot;&gt;Skipping the boring bits&lt;/h2&gt;

&lt;p&gt;It took me a lot of fiddling to get &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nx_client&lt;/code&gt; to this point - none of which is interesting enough to write about. It’s a nifty little tool I think, way beyond what’s needed for the initial backup use case. Which now is as simple as putting together something like this:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;uploading &amp;lt;APP&amp;gt; backup&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;file &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /path/to/backup/files/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do
    &lt;/span&gt;nx_client.sh &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; /home/user/.nx_client &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$file&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; /Backup/APP/
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Call that from your crontab, and you’ll have a simple pipeline that takes a bunch of files you want off-site and pushes them to a Nextcloud instance.&lt;/p&gt;

&lt;h2 id=&quot;so-whats-with-docspell&quot;&gt;So what’s with docspell?&lt;/h2&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nx_client&lt;/code&gt; and backup scripts above work for anthing that’s a file, of course - so what’s with the docspell data (docspell is using &lt;em&gt;postgresql&lt;/em&gt;)? As usual, people have been here before, in this case there is this nice &lt;a href=&quot;https://github.com/prodrigestivill/docker-postgres-backup-local&quot;&gt;dockerized pgbackup-to-local-filesystem&lt;/a&gt; solution, courtesy of &lt;a href=&quot;https://github.com/prodrigestivill&quot;&gt;PauRE&lt;/a&gt;. With that, the backup chain to Nextcloud looks like this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;dockspell/postgresql&lt;/li&gt;
  &lt;li&gt;docker-postgres-backup-local&lt;/li&gt;
  &lt;li&gt;cronjob calling a simple backup script (see previous section)&lt;/li&gt;
  &lt;li&gt;nx_client for performing the uploads&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Works like a charm - one more dandelion seed taken care of!&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Nothing much - the profusion of different styles of statements { and brackets! &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[] [[]] () (())&lt;/code&gt; } in the context of bash &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;if&lt;/code&gt; statements is not pretty&lt;/li&gt;
  &lt;li&gt;Nextcloud rocks, as usual&lt;/li&gt;
  &lt;li&gt;The most complicated part of all this is: which files to push off-site, how often? (compare with what pgbackup exports)&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">With the recent instantiation of my simple scanning station, there is now another data sink in my home network that wants backup. And in the case of the docspell database, we’re looking at quite relevant data, so a backup definitely is called for. Where backups are concerned I am partial to the dandelion strategy: spread your data around often, and to all kinds of places. One of the locations that I like to use is the Nextcloud instance that is covering all our “Cloud data” needs.</summary></entry><entry><title type="html">Simple Scanning Station</title><link href="https://www.danielkrippner.de/scanningstation" rel="alternate" type="text/html" title="Simple Scanning Station" /><published>2022-02-12T00:00:00-06:00</published><updated>2022-02-12T00:00:00-06:00</updated><id>https://www.danielkrippner.de/scanningstation</id><content type="html" xml:base="https://www.danielkrippner.de/scanningstation">&lt;p&gt;Mostly out of Corona-induced boredom I decided I wanted a document scanning pipeline to get any relevant paperwork into a document management system like doscpell, with as little effort (both cost-wise and from a UX perspective) as possible. So I built a simple and hands-off scanning station with my raspberry home automation system, running on 64bit Ubuntu and with mostly standard packages / components.
The scanning station works with a Fujitsu S1100 portable scanner, and implements a very simple workflow:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;turn on scanner (by opening the front and top covers)&lt;/li&gt;
  &lt;li&gt;feed in the document to be scanned; this will start the scan and result in a pdf version of the document file appearing in the output folder (to be ingested by &lt;em&gt;docspell&lt;/em&gt;)&lt;/li&gt;
  &lt;li&gt;the single button of the S1100 is used to implement a multi-page document mode:
    &lt;ul&gt;
      &lt;li&gt;push the button to start multi-page mode&lt;/li&gt;
      &lt;li&gt;feed in document pages&lt;/li&gt;
      &lt;li&gt;push button again to end multi-page mode, resulting in a single pdf file with all scanned pages placed in output folder&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;close the scanner covers - done&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This article gives a quick rundown of the configuration steps necessary to (re)create this setup. It is intended to work with a document management system like &lt;a href=&quot;https://docspell.org&quot;&gt;&lt;em&gt;docspell&lt;/em&gt;&lt;/a&gt;, which consumes the generated scans and makes them available in a document database.&lt;/p&gt;

&lt;h2 id=&quot;saned&quot;&gt;saned&lt;/h2&gt;

&lt;p&gt;The fundamental building block for our scanner pipeline is of course &lt;a href=&quot;http://www.sane-project.org&quot;&gt;&lt;em&gt;sane&lt;/em&gt;&lt;/a&gt;. Basic setup for the Fujitsu S1100 is quite simple and the device works out of the box - after adding the &lt;em&gt;.nal&lt;/em&gt; driver files from either the Windows driver CABs or the internet to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/usr/share/sane/epjitsu/&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This should be enough to fire up the scanner:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;start &lt;em&gt;saned&lt;/em&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo systemctl start saned.socket&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;try &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sane-find-scanner -q&lt;/code&gt;, make sure the device is listed&lt;/li&gt;
  &lt;li&gt;then try &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanimage -L&lt;/code&gt;, which should result in the scanner buzzing a bit and a message that sane has identified and set up the device&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;If this results in permission errors, make sure the user you’re running this with is a mamber of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanner&lt;/code&gt; group (Ubuntu default setup), or prefix a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sudo&lt;/code&gt; to these commands.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;scanservjs&quot;&gt;scanservjs&lt;/h2&gt;

&lt;p&gt;At this point it is possible to go ahead with a UI frontend for sane-scanning like &lt;a href=&quot;https://github.com/sbs20/scanservjs&quot;&gt;&lt;em&gt;scanservjs&lt;/em&gt;&lt;/a&gt;.
I like to put things into containers as much as possible, for ease of deployment (especially, easy of re-creating deployments). &lt;em&gt;scanservjs&lt;/em&gt; is available as a docker image of course - below I include a simple docker-compose file that pulls up &lt;em&gt;scanservjs&lt;/em&gt; to work with &lt;em&gt;saned&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;There is one thing needed to make this play seamlessly from inside a docker container: while it is possible to map (usb) device inodes into the container, this only works as long as the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/bus/usb/...&lt;/code&gt; entry for our scanner doesn’t change. Which it will as soon as we close/open the device cover flaps in between scanning sessions.&lt;/p&gt;

&lt;p&gt;To get around that, we can tell the natively running &lt;em&gt;saned&lt;/em&gt; to expose device access via a network port. To do this, add the container’s IP address range to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/saned.conf&lt;/code&gt; file in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Access List&lt;/code&gt; section. To find out what IP address the &lt;em&gt;scanserv&lt;/em&gt; container is running with, use this command:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker container inspect scanservjs | &lt;span class=&quot;nb&quot;&gt;grep &lt;/span&gt;IPAddress
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In my case I’m adding the following address block to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;saned.conf&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;## Access List&lt;/span&gt;
172.21.0.1/24
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Inside &lt;em&gt;scanservjs&lt;/em&gt;’ docker container the sane service now needs to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;net&lt;/code&gt; driver, and connect to the saned instance running on the host system. A rudimentary docker-compose file to make all of this happen looks like this:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;na&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3&quot;&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;services&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;na&quot;&gt;scanservjs&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;container_name&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;scanservjs&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;masterokhan/pi-scanservjs:latest&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unless-stopped&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;extra_hosts&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;host.docker.internal:host-gateway&quot;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;SANED_NET_HOSTS=&amp;lt;host-address&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/opt/scanserv/output:/app/data/output&apos;&lt;/span&gt;
      &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/opt/scanserv/config:/app/config&apos;&lt;/span&gt;
    &lt;span class=&quot;na&quot;&gt;restart&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;unless-stopped&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;scanbd-and-scanbm&quot;&gt;scanbd and scanbm&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;scanservjs&lt;/em&gt; is a smooth frontend for interactive scanning, and if that’s what is needed you’re done at this point.
However I want to build an automated scanning pipeline with as little user interaction needed as possible. So we are not looking for an interactive UI, but rather want to streamline the entire process.&lt;/p&gt;

&lt;p&gt;To do this we need a service that continuously polls the scanner for events like “button pressed” or “paper detected”, and immediately initiates the scanning process.
As usual people have been there before, and have created the &lt;a href=&quot;https://manpages.debian.org/bullseye/scanbd/scanbd.8.en.html&quot;&gt;&lt;em&gt;scanbd&lt;/em&gt;&lt;/a&gt; service to do just that. A quick &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;apt install scanbd&lt;/code&gt; gets the necessary things in place, however our setup for scanbd is slightly more involved. I am not going to rehash the scanbd setup here, there are &lt;a href=&quot;https://wiki.archlinux.org/title/Scanner_Button_Daemon&quot;&gt;multiple&lt;/a&gt; &lt;a href=&quot;https://sodocumentation.net/raspberry-pi/topic/6701/create-a-scan-station-with-scanbd--raspbian-&quot;&gt;articles&lt;/a&gt; out there describing the steps.&lt;/p&gt;

&lt;p&gt;What is important:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;really copy &lt;strong&gt;all&lt;/strong&gt; files from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/sane.d/&lt;/code&gt; to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/scanbd/&lt;/code&gt; configuration; I initially forgot to include &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sane.conf&lt;/code&gt;, which results in scanbm not working as expected&lt;/li&gt;
  &lt;li&gt;… &lt;em&gt;scanbm&lt;/em&gt; is a management-proxy in front of &lt;em&gt;scanbd&lt;/em&gt;, which monitors client interactions on the &lt;em&gt;saned&lt;/em&gt; port, and stops scanbd polling to allow other clients access to the scanner&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More interesting is setting up the script actions for &lt;em&gt;scanbd&lt;/em&gt; to execute on various scanner events. To enable the workflow described above, my configuration reacts to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paperload&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scan&lt;/code&gt; events, which represent paper being fed and the button being pressed, respectively.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I wanted to use the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;powersave&lt;/code&gt; event as well, to clean up the multipage environment (see below), thinking that it would occur when the scanner covers are being closed. Turns out the device enters powersave after a few seconds of inactivity, so I had to dismiss that idea.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you want to know what events your scanner supports, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanimage -A&lt;/code&gt; can give you an overview. Also have a look at the files in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/scanbd/scanner.d&lt;/code&gt;, maybe there is something in there that works with your device.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd.conf&lt;/code&gt; file, plus the scripts in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts&lt;/code&gt;, contain the logic to implement our hands-off scanning station workflow. In principle there are two parts to make this work:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;paperload&lt;/code&gt; the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scripts/scan.script&lt;/code&gt; is started, which tells the scanner to
    &lt;ul&gt;
      &lt;li&gt;grab a tiff from the inserted document, into a tmp directory&lt;/li&gt;
      &lt;li&gt;convert that into a pdf file&lt;/li&gt;
      &lt;li&gt;move the pdf to the final output folder and clean up, &lt;strong&gt;unless&lt;/strong&gt; we are in multipage mode (see below)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scan&lt;/code&gt; button press we initiate multi-page mode, which
    &lt;ul&gt;
      &lt;li&gt;creates a multipage-flag file on first press&lt;/li&gt;
      &lt;li&gt;if that flag is set during page scan, created documents are not moved to the final output folder but stay in the tmp folder, until&lt;/li&gt;
      &lt;li&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scan&lt;/code&gt; button is pressed a second time,&lt;/li&gt;
      &lt;li&gt;which collates all the collected single-page documents into one multipage pdf,&lt;/li&gt;
      &lt;li&gt;moves that into the output folder&lt;/li&gt;
      &lt;li&gt;and cleans everything up including the multipage-flag file&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Look at the scripts below for details on how things work. The main thing to be mindful of is setting up the scripts and folders with the necessary permissions so that everything can work as desired. I am doing the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd.conf&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scripts/*&lt;/code&gt; are managed in a gitlab repository, and checked out locally into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/scanserv/scanbd&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/scanbd/scanbd.conf&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/scanbd/scripts/&lt;/code&gt; are links to that local repo&lt;/li&gt;
  &lt;li&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;output&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tmp&lt;/code&gt; folders are also located in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt/scanserv/&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;saned&lt;/em&gt; and &lt;em&gt;scanbd&lt;/em&gt; deamons run as user &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;saned&lt;/code&gt;, group &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanner&lt;/code&gt; by default, so we allow the required access to these folders:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;chmgrp &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; scanner /opt/scanserv/output /opt/scanserv/temp
&lt;span class=&quot;nb&quot;&gt;sudo chmod&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-R&lt;/span&gt; g+w /opt/scanserv/output /opt/scanserv/tmp
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Testing all of this can be done by running the scripts individually - just keep in mind that you’re likely going to do that with a different user than what &lt;em&gt;saned&lt;/em&gt; will be using. The scripts contain syslog output that can he observed using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tail -f /var/log/syslog&lt;/code&gt;.
Once everything appears to work, start the &lt;em&gt;scanbd&lt;/em&gt; and &lt;em&gt;scanbm&lt;/em&gt; deamons using&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl start scanbd.service
&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl start scanbm.socket
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Once all of this is running, instruct the document management system to pick up files from the output folder defined in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts/vars.scripts&lt;/code&gt; - this is also where other relevant directories and properties like scanning mode and resolution are defined.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;What is missing from the setup is some user feedback when multipage mode is active - I’ve no good ideas how to do that, as there is not way to get the scanner to make noises or change the LED settings.&lt;/li&gt;
  &lt;li&gt;Otherwise this is a nifty setup, works well even with a cheap simplex scanner.&lt;/li&gt;
  &lt;li&gt;Setting up docspell on a 4B Raspi requires tuning down language processing settings, and docspell in general hasbn’t been the most robust experience for me. Might write a dedicated post about that setup.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&quot;scanbdscriptsvarsscript&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts/vars.script&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;BASEDIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/opt/scanserv
&lt;span class=&quot;nv&quot;&gt;TMPDIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$BASEDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/scanbd/tmp
&lt;span class=&quot;nv&quot;&gt;OUTPUTDIR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$BASEDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/output
&lt;span class=&quot;nv&quot;&gt;MULTIPAGE_MODE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$BASEDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/scanbd/multimode.flag

&lt;span class=&quot;nv&quot;&gt;MODE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;Gray
&lt;span class=&quot;nv&quot;&gt;RESOLUTION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;300
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scanbdscriptsscanscript&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts/scan.script&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/scanbd/scripts/vars.script

&lt;span class=&quot;c&quot;&gt;# We need tiff2pdf installed&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; tiff2pdf &amp;amp;&amp;gt; /dev/null
&lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ERROR scanning on &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: missing tiff2pdf executable!&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fi


&lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Begin of &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_ACTION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Scan_&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;{ print $1 strftime(&quot;%Y%m%d_%H%M%S&quot;) }&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
scanimage &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.tiff &lt;span class=&quot;nt&quot;&gt;--format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;tiff &lt;span class=&quot;nt&quot;&gt;--mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--resolution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$RESOLUTION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; epjitsu
tiff2pdf &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; A4 &lt;span class=&quot;nt&quot;&gt;-F&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-o&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.pdf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.tiff


&lt;span class=&quot;c&quot;&gt;# If we&apos;re not in MULTIPAGE_MODE move file to OUTPUT and clean up&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MULTIPAGE_MODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mv&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.pdf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OUTPUTDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-fr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;else
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.tiff
  logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;MULTIPAGE scan on device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;, leaving scan in place in &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;End of &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_ACTION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scanbdscriptsmultipagescript&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts/multipage.script&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/scanbd/scripts/vars.script


&lt;span class=&quot;c&quot;&gt;# We need tiff2pdf installed&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# (gs is also used below, but should be available by default in most Linux environments)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; tiff2pdf &amp;amp;&amp;gt; /dev/null
&lt;span class=&quot;k&quot;&gt;then
  &lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ERROR entering MULTIPAGE mode for &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: missing tiff2pdf executable!&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;exit
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;


&lt;span class=&quot;c&quot;&gt;# are we already in multipage mode?&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MULTIPAGE_MODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
  if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ERROR finalizing multipage session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;: TMPDIR not available (&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;)&quot;&lt;/span&gt;
    /etc/scanbd/scripts/multipage_cleanup.script
    &lt;span class=&quot;nb&quot;&gt;exit
  &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# wrap up multipage session - collate scanned documents, move to downstream processing, clean up&lt;/span&gt;
  logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Finalize multipage session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;nv&quot;&gt;COUNT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;find &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-maxdepth&lt;/span&gt; 1 &lt;span class=&quot;nt&quot;&gt;-name&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;*.pdf&apos;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;wc&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$COUNT&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-gt&lt;/span&gt; 0 &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Concatenating &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$COUNT&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; files for multipage session on device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

    &lt;span class=&quot;c&quot;&gt;# collate all pdfs into one file and move that to output folder&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;MultiScan_&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;awk&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;{ print $1 strftime(&quot;%Y%m%d_%H%M%S&quot;) }&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;
    gs &lt;span class=&quot;nt&quot;&gt;-dBATCH&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-dNOPAUSE&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-q&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-sDEVICE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;pdfwrite &lt;span class=&quot;nt&quot;&gt;-dAutoRotatePages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/None &lt;span class=&quot;nt&quot;&gt;-sOutputFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.pdf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.pdf
    &lt;span class=&quot;nb&quot;&gt;mv&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$filename&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;.pdf &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$OUTPUTDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;else
      &lt;/span&gt;logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;No scanned files found for session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;

  /etc/scanbd/scripts/multipage_cleanup.script
  logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Multipage session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; wrapped up&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# prepare multipage session&lt;/span&gt;
  logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Enter multipage session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

  &lt;span class=&quot;c&quot;&gt;# create tmp dir for our multi-page scans, set MULTIPAGE flag to true&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MULTIPAGE_MODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

  logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Multipage session for device &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SCANBD_DEVICE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; set up&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;scanbdscriptsmultipage_cleanupscript&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scripts/multipage_cleanup.script&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/scanbd/scripts/vars.script

logger &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scanbd: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$0&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Cleaning up multipage-mode residuals&quot;&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-fr&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$TMPDIR&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$MULTIPAGE_MODE&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;excerpt-from-scanbdscanbdconf&quot;&gt;excerpt from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;scanbd/scanbd.conf&lt;/code&gt;`&lt;/h3&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;action scan &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    filter &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^scan.*&quot;&lt;/span&gt;
        numerical-trigger &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            from-value &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1
            to-value   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    desc   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Trigger multipage mode&quot;&lt;/span&gt; 
    script &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;multipage.script&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

action paperload &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    filter &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;^page-loaded.*&quot;&lt;/span&gt;
        numerical-trigger &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            from-value &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 0
            to-value   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 1
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    desc   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Scan to file&quot;&lt;/span&gt;
    script &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;scan.script&quot;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">Mostly out of Corona-induced boredom I decided I wanted a document scanning pipeline to get any relevant paperwork into a document management system like doscpell, with as little effort (both cost-wise and from a UX perspective) as possible. So I built a simple and hands-off scanning station with my raspberry home automation system, running on 64bit Ubuntu and with mostly standard packages / components. The scanning station works with a Fujitsu S1100 portable scanner, and implements a very simple workflow:</summary></entry><entry><title type="html">3 Mac keyboards</title><link href="https://www.danielkrippner.de/mackeyboard" rel="alternate" type="text/html" title="3 Mac keyboards" /><published>2022-02-11T00:00:00-06:00</published><updated>2022-02-11T00:00:00-06:00</updated><id>https://www.danielkrippner.de/mackeyboard</id><content type="html" xml:base="https://www.danielkrippner.de/mackeyboard">&lt;p&gt;Quick interlude: the &lt;a href=&quot;https://www.danielkrippner.de/mackeyboard&quot;&gt;Apple keyboard love&lt;/a&gt; seems to go both ways. A couple of weeks ago, the keyboard of the barely 2 months old M1 Macbook Pro died. Just like that - no keypresses registered any more, backlight off, rebooting etc didn’t to anything. The touchpad continued to funtion normally, however.&lt;/p&gt;

&lt;h2 id=&quot;clever-boot-options-ux-choices&quot;&gt;Clever boot options UX choices&lt;/h2&gt;

&lt;p&gt;The only thing that still operated was the power button/key - enough to turn the machine off and on, and to enter the boot options menu. There is an option for booting into Safe Mode - that requires the shift key to be pressed when clicking the corresponding option. Duh.
I do have a external USB keyboard available of course - but no 30 bucks Apple USB-A Adapter. Just a ‘regular’ one that of course didn’t do anything when connected to the Mac.&lt;/p&gt;

&lt;h2 id=&quot;repair-1&quot;&gt;Repair #1&lt;/h2&gt;

&lt;p&gt;Allright - so let’s test Apple customer service. Called the hotline (looong wait time!), which ended in the Apple support engineer setting up a Genius Bar appointment at the closes Apple Store. Or trying to, because the reservation system was acting funky… Having been pointed at that though, I registered an appointment on my own some hours later.
Had to wait a couple of days for that session, because of course the keyboard died on a Saturday and the next time slot I could make available for the Store visit was Tuesday. Anyways, went there and sat with the nice support guy who did diagnostics and took my computer in for repair.
Two days later I was texted to collect my machine again, which I did. They replaced the top-cover-cum-keyboard, plus some other stuff - got to keep the disk and data though.&lt;/p&gt;

&lt;h2 id=&quot;repair-2&quot;&gt;Repair #2&lt;/h2&gt;

&lt;p&gt;… and was able to work with the computer until the next day. Because the next day, the keyboard died again. Did I mention that this is by far the most expensive piece of hardware I ever bought? First Apple computer I ever bought? Going splendidly, so far.
Being wise to the Genius Bar thing, I did the moves again and brought the computer in again. This time they sent it off to a repair center one country over, to be gone about a week. I didn’t have to drive to the Store and back again to pick it up, but the machine was sent to my home address one week later as promised. They replaced “more” - mainboard, disk, topcase, etc. Probably the only thing untouched is the serial number.&lt;/p&gt;

&lt;h2 id=&quot;backup-restore---what&quot;&gt;Backup restore - what?&lt;/h2&gt;

&lt;p&gt;With the Mac back with an new disk, I wanted to make use of my time machine backup to get back up and running. That turned out to be another strange experience: starting up I was given the option to restore from backup - nice! Selected that, it went and copied files for a couple of hours. When that was done I was asked to create a new user. Wait - if my user hasn’t been (re)created with the restore, where the heck did it just copy all that data to?! Turns out that this is indeed a good question, one without an answer. Because when logging in with the newly created user the disk was “empty”, as in “the 200GB that should have been taken up with restored data are nowhere to be found”.
Oh well, ok then. I know how I’ll be spending the evening.&lt;/p&gt;

&lt;h2 id=&quot;mixed-bag&quot;&gt;Mixed bag&lt;/h2&gt;

&lt;p&gt;This episode left me with mixed feelings. The definive downer is the obvious fact that a very expensive piece of supposedly high-end kit breaks after just 2 months of light use. I’ve never had this kind of issue with any notebook, in 20 years of continually working with many different makes&amp;amp;models (never Apple, though). So to experience this with the first Apple computer I’m using in my life is a bummer, and hopefully a definitive outlier. This also better not happen after warranty - the repair bills (that I didn’t have to pay but have seen nonetheless) are no joke.&lt;/p&gt;

&lt;p&gt;Also irritating are the strange design choices Apple has made especially around how backup-restore onto a fresh machine works. I stronly suspect that this was a case of PEBKAC - but if Apple UX is so great then this sort of user error just should not happen. That it is not possible to use either mouse/trackpad &lt;em&gt;OR&lt;/em&gt; keyboard to boot into safe mode is a niche issue, but an avoidable one - if you’d prioritize robustness over design aesthetics.&lt;/p&gt;

&lt;p&gt;The upshot is that in those two weeks I missed the Mac quite a bit. I wanted to do stuff, and while this machine for me is pure private plaything and there’s no deadlines or anything, I really was looking forward to getting it back.
Finally I believe there is a strong case of buy-in-bias at work here. I’ve now invested emotions and quite some extra time into this thing (3 trips to the Apple Store and back at 30 mins each…), I’m growing attached.&lt;/p&gt;

&lt;p&gt;So please, just work now!&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Apple Support is good - not surprising considering the cost of the products, but good people there.&lt;/li&gt;
  &lt;li&gt;I now own an Apple USB-A adapter - I guess there’s no turning back after this point.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">Quick interlude: the Apple keyboard love seems to go both ways. A couple of weeks ago, the keyboard of the barely 2 months old M1 Macbook Pro died. Just like that - no keypresses registered any more, backlight off, rebooting etc didn’t to anything. The touchpad continued to funtion normally, however.</summary></entry><entry><title type="html">Of course we (only) do AirPrint!</title><link href="https://www.danielkrippner.de/airprint" rel="alternate" type="text/html" title="Of course we (only) do AirPrint!" /><published>2021-12-21T00:00:00-06:00</published><updated>2021-12-21T00:00:00-06:00</updated><id>https://www.danielkrippner.de/airprint</id><content type="html" xml:base="https://www.danielkrippner.de/airprint">&lt;p&gt;After approximately one month, the Apple journey is going well. Even picking up speed one could say, as I’m beginning to feel comfortable, or even at home a lot of the time. Still not closer to appreciating how the application switcher works, though ;-)&lt;/p&gt;

&lt;p&gt;As I’ve done a full ecosystem switch, including mobile phone and tablet, also for these devices there is a need to interoperate with things like printers that exist in our household. This writeup is about how that worked out for me.&lt;/p&gt;

&lt;h2 id=&quot;cups-is-an-apple-project-so-how-hard-can-it-be&quot;&gt;CUPS is an Apple project, so how hard can it be?&lt;/h2&gt;

&lt;p&gt;Although I did not realize this before, the venerable &lt;a href=&quot;https://www.cups.org&quot;&gt;CUPS printing system&lt;/a&gt; is an Apple-driven project. That is good. Especially because Apple products (iOS devices, specifically) don’t do anything with IPP, nor could I find a manufacturer ‘driver app’ to connect with our little oldish Samsung color laser printer. Instead, Apple products are looking for AirPrint devices…&lt;/p&gt;

&lt;p&gt;As I have a Raspberry Pi running our home automation, DNS filter and a bunch of other around-the-house services, there should be something we can do with that. Open source to the rescue: of course there is! A combination of CUPS and &lt;a href=&quot;https://avahi.org&quot;&gt;Avahi&lt;/a&gt; will act as a relay, making CUPS-driven printers available in the local network via Avahi service discovery.&lt;/p&gt;

&lt;p&gt;A first quick trial, installing CUPS and Avahi directly in the Pi’s Ubuntu host system, proves that this works quite painlessly. But all other workloads on my Pi are containerized and designed to make the overall setup as reproducible and modular as possible…&lt;/p&gt;

&lt;h2 id=&quot;is-there-anything-out-there&quot;&gt;Is there anything out there?&lt;/h2&gt;

&lt;p&gt;Yes and no. What we want is a ready-made docker image that acts as our AirPrint relay, with minimal configuration and fuss needed. There are some Docker recipes, many of which seem to be descendants of &lt;a href=&quot;https://github.com/quadportnick/docker-cups-airprint&quot;&gt;quadportnicks docker-cups-avahi project&lt;/a&gt;, with associated images on dockerhub. I couldn’t find one that worked for me though - I was looking for a combination of arm64 support, included drivers for my Samsung printer, and maybe not being abandoned years ago.
So after looking around a bit, I decided to hit that fork button and adapt something for my needs.&lt;/p&gt;

&lt;h2 id=&quot;what-do-we-want&quot;&gt;What do we want?&lt;/h2&gt;

&lt;p&gt;My AirPrint relay image should have the following properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Include drivers for my printer, of course. Maybe even be a generic thing that comes with all available drivers, to become more widely useful?&lt;/li&gt;
  &lt;li&gt;Allow persistent storage of printer-related configuration outside of the container image, while stuff like cups configuration should ‘just work’ and stay out of the way otherwise.&lt;/li&gt;
  &lt;li&gt;Size is a concern too, within limits - generic usefulness means we won’t optimize for size, but no need to be wasteful either.&lt;/li&gt;
  &lt;li&gt;Support for 64bit arm architectures. Maybe even go multi-arch?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The aforementioned cups-avahi-airprint project does cover a lot of these bases already, so let’s fork that. Actually, I forked &lt;a href=&quot;https://github.com/chuckcharlie/cups-avahi-airprint&quot;&gt;a fork&lt;/a&gt; of that project, for no good reason other than that I’ve been looking at it at the time.&lt;/p&gt;

&lt;h2 id=&quot;building-an-airprint-relay&quot;&gt;Building an &lt;a href=&quot;https://github.com/AnotherDaniel/airprint-relay&quot;&gt;AirPrint Relay&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;There was actually a reason for basing off chuckcharlies version of cups-avahi-airprint: I liked the idea of using Alpine as base image. However, after spending too much time trying to find out whether my old Samsung CLP-365 was supported by any package on that distro and not finding anything useful, I reverted the build back to Ubuntu (my printer is supported by ubuntu package &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;printer-driver-foo2zjs&lt;/code&gt;). Ubuntu does provide a quite minimal base image for docker stuff, and while it is not as small as Alpine, I was willing to take the size hit to just get my printer supported and move on with things.&lt;/p&gt;

&lt;p&gt;The switch to Ubuntu brought one problem: during build, the systems wants manual input for configuring the tzdata package. Luckily the internet has a solution for that (&lt;a href=&quot;https://github.com/AnotherDaniel/airprint-relay/blob/master/Dockerfile&quot;&gt;see the Dockerfile&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Next step: add all printer drivers to the image build that I could find. I’ll thank myself in the future should I ever switch hardware, plus maybe this way the image becomes useful for other people too.&lt;/p&gt;

&lt;p&gt;That’s most of the visible changes already. I spent a lot of time learning how to get this image to correctly register with my Traefik router, so that the CUPS dashboard becomes reachable via a nice name instead of IP and port. The problem was that CUPS refuses requests that come with a wrong host entry in the header (wrong as far as CUPS is concerned). The fix for that is a combination of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cupsd.conf&lt;/code&gt; and Traefik settings:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cupsd.conf&lt;/code&gt; should contain the following lines&lt;/p&gt;

&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;err&quot;&gt;Port&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;*:631&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# this replaces the default &apos;Listen ...&apos; directive
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;ServerAlias&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This Traefik label is needed in the AirPrint Relay docker-compose.yml:&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;na&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;traefik.http.services.airprint-relay.loadbalancer.passhostheader=false&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The latter took me quite some digging to figure out - but with these, Traefik routing works for me.&lt;/p&gt;

&lt;p&gt;The original project came with some scripting- and Python magic for handling CUPS startup and Avahi service file creation from CUPS-configured printers, which I didn’t change much beyond minor naming convention alignments and adaptions around current Ubuntu versions of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;adduser&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;addgroup&lt;/code&gt;. Oh, and I fixed one of the Python-generated Avahi service fields to provide printer location (as it’s used by MacOS), instead of printer info.&lt;/p&gt;

&lt;p&gt;The final steps were brushing up the project README, and adding a multi-arch build action following the regular &lt;a href=&quot;https://www.docker.com/blog/multi-arch-build-and-images-the-simple-way/&quot;&gt;docker documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-result&quot;&gt;The Result&lt;/h2&gt;

&lt;p&gt;The result of all of this is available for easy consumption from &lt;a href=&quot;https://hub.docker.com/r/agoodcontainer/airprint-relay&quot;&gt;dockerhub&lt;/a&gt; - a one-click solution for deploying an AirPrint relay service into your home network.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;AirPrint is a sweet user experience, once it works&lt;/li&gt;
  &lt;li&gt;I came across the &lt;a href=&quot;https://ohmyz.sh&quot;&gt;oh-my-zsh project&lt;/a&gt;, which boosts working with a shell to a new level&lt;/li&gt;
  &lt;li&gt;If you’re feeling festive, &lt;a href=&quot;https://github.com/chockenberry/Notchmeister&quot;&gt;Notchmeister will deliver&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">After approximately one month, the Apple journey is going well. Even picking up speed one could say, as I’m beginning to feel comfortable, or even at home a lot of the time. Still not closer to appreciating how the application switcher works, though ;-)</summary></entry><entry><title type="html">Two weeks of Apple</title><link href="https://www.danielkrippner.de/after-two-weeks" rel="alternate" type="text/html" title="Two weeks of Apple" /><published>2021-11-29T00:00:00-06:00</published><updated>2021-11-29T00:00:00-06:00</updated><id>https://www.danielkrippner.de/after-two-weeks</id><content type="html" xml:base="https://www.danielkrippner.de/after-two-weeks">&lt;p&gt;It’s been two weeks now since I started to grow my Apple garden - one of the M1 MacBooks, a current iPhone, and recently a M1 iPad to complement my core device needs. The major rants I just had to get off my chest were about the &lt;a href=&quot;https://www.danielkrippner.de/mackeyboard&quot;&gt;keyboard layout&lt;/a&gt;, and the &lt;a href=&quot;https://www.danielkrippner.de/appswitcher&quot;&gt;Application Switcher&lt;/a&gt;.
Since then I’ve been playing with the system, getting used to things. This is an update and comment on some of the things I’ve been thinking.&lt;/p&gt;

&lt;h2 id=&quot;keyboard-revisited&quot;&gt;Keyboard revisited&lt;/h2&gt;

&lt;p&gt;After about a week I’m actually getting used to this layout, and (mostly) don’t need to look up the locations of special characters any more. I’m still not enthusiastic about the modifier key proliferation, but I get by… to the point where the keyboard on my work machine is beginning to throw me off :-)
There is one thing that I’m really not happy with, on a professional machine in this price range: the ridiculous half-size up-down cursor keys.&lt;/p&gt;

&lt;h2 id=&quot;app-switcher&quot;&gt;App Switcher&lt;/h2&gt;

&lt;p&gt;I’m not really using the App Switcher, thus avoiding being annoyed by it. Funnily, the one App that I actually don’t want to re-appear when minimized apparently is buggy, and does. Sigh.
I still think that having minimized Apps appear in the switcher without being able to do anything with them is the stupidest UX ever.&lt;/p&gt;

&lt;h2 id=&quot;browser-trials&quot;&gt;Browser trials&lt;/h2&gt;

&lt;p&gt;An advanced symptom of my Appleification process might be the fact that I’m trying to switch to Safari as my main browser. It is clean and fast, that I like. Beyond bookmarks, there’s no sync options to any other browsers, which is not nice for poly-system users. One thing that Safari makes very visible is the monetization of almost everything within the Apple ecosystem.&lt;/p&gt;

&lt;h2 id=&quot;everything-costs-almost&quot;&gt;Everything costs (almost)&lt;/h2&gt;

&lt;p&gt;Coming from Linux and Android, I am not too thrilled about the state of OSS software in the Apple ecosystem. The main applications exist, that is fine. But there seems to be little room/motivation for high-quality smaller projects that are abundant in Linux, and still quite present in an Android context.
And: almost everything costs money, especially via the App Store(s). With an unhealthy tendency towards subscription models, which I simply don’t like very much. Little surprise I guess, but it can be off-putting.&lt;/p&gt;

&lt;h2 id=&quot;there-is-something&quot;&gt;There is something&lt;/h2&gt;

&lt;p&gt;All of the niggly things aside, there is something about this line of products, how different devices feel like part of a family, how things normally just work. Except for the stock Mac Photos app, but that’s a story in itself.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;waymarks&quot;&gt;Waymarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Not entirely surprising, I’m getting used to Apple. It certainly still is intriguing enough to keep playing and learning.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Daniel Krippner</name><email>dk.mailbox@gmx.net</email></author><summary type="html">It’s been two weeks now since I started to grow my Apple garden - one of the M1 MacBooks, a current iPhone, and recently a M1 iPad to complement my core device needs. The major rants I just had to get off my chest were about the keyboard layout, and the Application Switcher. Since then I’ve been playing with the system, getting used to things. This is an update and comment on some of the things I’ve been thinking.</summary></entry></feed>